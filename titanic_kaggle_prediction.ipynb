{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.53:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x122088518>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data into Spark using DataFrames\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Titanic Data').getOrCreate()\n",
    "\n",
    "spark # prints what's in the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Survived: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the training data and create a DataFrames\n",
    "training_df = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"./data/train.csv\"))\n",
    "\n",
    "training_df # prints the DF structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|   4|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|  58|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|  20|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|  39|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|  14|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|  55|    0|    0|          248706|     16| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|   2|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|     13| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|  31|    1|    0|          345763|     18| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print some training data records and count from the DF\n",
    "training_df.show()\n",
    "training_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test data and create a DataFrames\n",
    "test_df = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"./data/test.csv\"))\n",
    "\n",
    "test_df # prints the DF structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0|          330911| 7.8292| null|       Q|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|  47|    1|    0|          363272|      7| null|       S|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|  62|    0|    0|          240276| 9.6875| null|       Q|\n",
      "|        895|     3|    Wirz, Mr. Albert|  male|  27|    0|    0|          315154| 8.6625| null|       S|\n",
      "|        896|     3|Hirvonen, Mrs. Al...|female|  22|    1|    1|         3101298|12.2875| null|       S|\n",
      "|        897|     3|Svensson, Mr. Joh...|  male|  14|    0|    0|            7538|  9.225| null|       S|\n",
      "|        898|     3|Connolly, Miss. Kate|female|  30|    0|    0|          330972| 7.6292| null|       Q|\n",
      "|        899|     2|Caldwell, Mr. Alb...|  male|  26|    1|    1|          248738|     29| null|       S|\n",
      "|        900|     3|Abrahim, Mrs. Jos...|female|  18|    0|    0|            2657| 7.2292| null|       C|\n",
      "|        901|     3|Davies, Mr. John ...|  male|  21|    2|    0|       A/4 48871|  24.15| null|       S|\n",
      "|        902|     3|    Ilieff, Mr. Ylio|  male|null|    0|    0|          349220| 7.8958| null|       S|\n",
      "|        903|     1|Jones, Mr. Charle...|  male|  46|    0|    0|             694|     26| null|       S|\n",
      "|        904|     1|Snyder, Mrs. John...|female|  23|    1|    0|           21228|82.2667|  B45|       S|\n",
      "|        905|     2|Howard, Mr. Benjamin|  male|  63|    1|    0|           24065|     26| null|       S|\n",
      "|        906|     1|Chaffee, Mrs. Her...|female|  47|    1|    0|     W.E.P. 5734| 61.175|  E31|       S|\n",
      "|        907|     2|del Carlo, Mrs. S...|female|  24|    1|    0|   SC/PARIS 2167|27.7208| null|       C|\n",
      "|        908|     2|   Keane, Mr. Daniel|  male|  35|    0|    0|          233734|  12.35| null|       Q|\n",
      "|        909|     3|   Assaf, Mr. Gerios|  male|  21|    0|    0|            2692|  7.225| null|       C|\n",
      "|        910|     3|Ilmakangas, Miss....|female|  27|    1|    0|STON/O2. 3101270|  7.925| null|       S|\n",
      "|        911|     3|\"Assaf Khalil, Mr...|female|  45|    0|    0|            2696|  7.225| null|       C|\n",
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print some test data records and count from the DF\n",
    "\n",
    "test_df.show()\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+------+----+-------+--------+\n",
      "|Survived|PassengerId|Pclass|   Sex| Age|   Fare|Embarked|\n",
      "+--------+-----------+------+------+----+-------+--------+\n",
      "|     0.0|          1|   3.0|  male|22.0|   7.25|       S|\n",
      "|     1.0|          2|   1.0|female|38.0|71.2833|       C|\n",
      "|     1.0|          3|   3.0|female|26.0|  7.925|       S|\n",
      "|     1.0|          4|   1.0|female|35.0|   53.1|       S|\n",
      "|     0.0|          5|   3.0|  male|35.0|   8.05|       S|\n",
      "|     0.0|          6|   3.0|  male|null| 8.4583|       Q|\n",
      "|     0.0|          7|   1.0|  male|54.0|51.8625|       S|\n",
      "|     0.0|          8|   3.0|  male| 2.0| 21.075|       S|\n",
      "|     1.0|          9|   3.0|female|27.0|11.1333|       S|\n",
      "|     1.0|         10|   2.0|female|14.0|30.0708|       C|\n",
      "|     1.0|         11|   3.0|female| 4.0|   16.7|       S|\n",
      "|     1.0|         12|   1.0|female|58.0|  26.55|       S|\n",
      "|     0.0|         13|   3.0|  male|20.0|   8.05|       S|\n",
      "|     0.0|         14|   3.0|  male|39.0| 31.275|       S|\n",
      "|     0.0|         15|   3.0|female|14.0| 7.8542|       S|\n",
      "|     1.0|         16|   2.0|female|55.0|   16.0|       S|\n",
      "|     0.0|         17|   3.0|  male| 2.0| 29.125|       Q|\n",
      "|     1.0|         18|   2.0|  male|null|   13.0|       S|\n",
      "|     0.0|         19|   3.0|female|31.0|   18.0|       S|\n",
      "|     1.0|         20|   3.0|female|null|  7.225|       C|\n",
      "+--------+-----------+------+------+----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start Data prep!\n",
    "\n",
    "# Prepare a training dataset by casting some of columns to required type!\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "training_ds = training_df.select(col('Survived').cast('float'),\n",
    "                                 col('PassengerId').cast('int'),\n",
    "                                 col('Pclass').cast('float'),\n",
    "                                 col('Sex'),\n",
    "                                 col('Age').cast('float'),\n",
    "                                 col('Fare').cast('float'),\n",
    "                                 col('Embarked')\n",
    "                                )\n",
    "training_ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+----+-------+--------+\n",
      "|PassengerId|Pclass|   Sex| Age|   Fare|Embarked|\n",
      "+-----------+------+------+----+-------+--------+\n",
      "|        892|   3.0|  male|34.5| 7.8292|       Q|\n",
      "|        893|   3.0|female|47.0|    7.0|       S|\n",
      "|        894|   2.0|  male|62.0| 9.6875|       Q|\n",
      "|        895|   3.0|  male|27.0| 8.6625|       S|\n",
      "|        896|   3.0|female|22.0|12.2875|       S|\n",
      "|        897|   3.0|  male|14.0|  9.225|       S|\n",
      "|        898|   3.0|female|30.0| 7.6292|       Q|\n",
      "|        899|   2.0|  male|26.0|   29.0|       S|\n",
      "|        900|   3.0|female|18.0| 7.2292|       C|\n",
      "|        901|   3.0|  male|21.0|  24.15|       S|\n",
      "|        902|   3.0|  male|null| 7.8958|       S|\n",
      "|        903|   1.0|  male|46.0|   26.0|       S|\n",
      "|        904|   1.0|female|23.0|82.2667|       S|\n",
      "|        905|   2.0|  male|63.0|   26.0|       S|\n",
      "|        906|   1.0|female|47.0| 61.175|       S|\n",
      "|        907|   2.0|female|24.0|27.7208|       C|\n",
      "|        908|   2.0|  male|35.0|  12.35|       Q|\n",
      "|        909|   3.0|  male|21.0|  7.225|       C|\n",
      "|        910|   3.0|female|27.0|  7.925|       S|\n",
      "|        911|   3.0|female|45.0|  7.225|       C|\n",
      "+-----------+------+------+----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare a test dataset by casting some of columns to required type!\n",
    "test_ds = test_df.select(\n",
    "                         col('PassengerId').cast('int'),\n",
    "                         col('Pclass').cast('float'),\n",
    "                         col('Sex'),\n",
    "                         col('Age').cast('float'),\n",
    "                         col('Fare').cast('float'),\n",
    "                         col('Embarked')\n",
    "                        )\n",
    "test_ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+---+---+----+--------+\n",
      "|Survived|PassengerId|Pclass|Sex|Age|Fare|Embarked|\n",
      "+--------+-----------+------+---+---+----+--------+\n",
      "|       0|          0|     0|  0|177|   0|       2|\n",
      "+--------+-----------+------+---+---+----+--------+\n",
      "\n",
      "+-----------+------+---+---+----+--------+\n",
      "|PassengerId|Pclass|Sex|Age|Fare|Embarked|\n",
      "+-----------+------+---+---+----+--------+\n",
      "|          0|     0|  0| 86|   1|       0|\n",
      "+-----------+------+---+---+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "training_ds.select([count(when(isnull(c), c)).alias(c) for c in training_ds.columns]).show() # todo: learn to query\n",
    "test_ds.select([count(when(isnull(c), c)).alias(c) for c in test_ds.columns]).show() # todo: learn to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+------+----+-------+--------+\n",
      "|Survived|PassengerId|Pclass|   Sex| Age|   Fare|Embarked|\n",
      "+--------+-----------+------+------+----+-------+--------+\n",
      "|     0.0|          1|   3.0|  male|22.0|   7.25|       S|\n",
      "|     1.0|          2|   1.0|female|38.0|71.2833|       C|\n",
      "|     1.0|          3|   3.0|female|26.0|  7.925|       S|\n",
      "|     1.0|          4|   1.0|female|35.0|   53.1|       S|\n",
      "|     0.0|          5|   3.0|  male|35.0|   8.05|       S|\n",
      "|     0.0|          7|   1.0|  male|54.0|51.8625|       S|\n",
      "|     0.0|          8|   3.0|  male| 2.0| 21.075|       S|\n",
      "|     1.0|          9|   3.0|female|27.0|11.1333|       S|\n",
      "|     1.0|         10|   2.0|female|14.0|30.0708|       C|\n",
      "|     1.0|         11|   3.0|female| 4.0|   16.7|       S|\n",
      "|     1.0|         12|   1.0|female|58.0|  26.55|       S|\n",
      "|     0.0|         13|   3.0|  male|20.0|   8.05|       S|\n",
      "|     0.0|         14|   3.0|  male|39.0| 31.275|       S|\n",
      "|     0.0|         15|   3.0|female|14.0| 7.8542|       S|\n",
      "|     1.0|         16|   2.0|female|55.0|   16.0|       S|\n",
      "|     0.0|         17|   3.0|  male| 2.0| 29.125|       Q|\n",
      "|     0.0|         19|   3.0|female|31.0|   18.0|       S|\n",
      "|     0.0|         21|   2.0|  male|35.0|   26.0|       S|\n",
      "|     1.0|         22|   2.0|  male|34.0|   13.0|       S|\n",
      "|     1.0|         23|   3.0|female|15.0| 8.0292|       Q|\n",
      "+--------+-----------+------+------+----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminate rows with null values in columns from the training dataset\n",
    "training_ds = training_ds.replace('?', None).dropna(how='any') # todo: learn the Dataset API\n",
    "training_ds.show()\n",
    "training_ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+----+-------+--------+\n",
      "|PassengerId|Pclass|   Sex| Age|   Fare|Embarked|\n",
      "+-----------+------+------+----+-------+--------+\n",
      "|        892|   3.0|  male|34.5| 7.8292|       Q|\n",
      "|        893|   3.0|female|47.0|    7.0|       S|\n",
      "|        894|   2.0|  male|62.0| 9.6875|       Q|\n",
      "|        895|   3.0|  male|27.0| 8.6625|       S|\n",
      "|        896|   3.0|female|22.0|12.2875|       S|\n",
      "|        897|   3.0|  male|14.0|  9.225|       S|\n",
      "|        898|   3.0|female|30.0| 7.6292|       Q|\n",
      "|        899|   2.0|  male|26.0|   29.0|       S|\n",
      "|        900|   3.0|female|18.0| 7.2292|       C|\n",
      "|        901|   3.0|  male|21.0|  24.15|       S|\n",
      "|        903|   1.0|  male|46.0|   26.0|       S|\n",
      "|        904|   1.0|female|23.0|82.2667|       S|\n",
      "|        905|   2.0|  male|63.0|   26.0|       S|\n",
      "|        906|   1.0|female|47.0| 61.175|       S|\n",
      "|        907|   2.0|female|24.0|27.7208|       C|\n",
      "|        908|   2.0|  male|35.0|  12.35|       Q|\n",
      "|        909|   3.0|  male|21.0|  7.225|       C|\n",
      "|        910|   3.0|female|27.0|  7.925|       S|\n",
      "|        911|   3.0|female|45.0|  7.225|       C|\n",
      "|        912|   1.0|  male|55.0|   59.4|       C|\n",
      "+-----------+------+------+----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminate rows with null values in columns from the test dataset\n",
    "test_ds = test_ds.replace('?', None).dropna(how='any') # todo: learn the Dataset API\n",
    "test_ds.show()\n",
    "test_ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+------+----+-------+--------+------+-------+\n",
      "|Survived|PassengerId|Pclass|   Sex| Age|   Fare|Embarked|Gender|Boarded|\n",
      "+--------+-----------+------+------+----+-------+--------+------+-------+\n",
      "|     0.0|          1|   3.0|  male|22.0|   7.25|       S|   0.0|    0.0|\n",
      "|     1.0|          2|   1.0|female|38.0|71.2833|       C|   1.0|    1.0|\n",
      "|     1.0|          3|   3.0|female|26.0|  7.925|       S|   1.0|    0.0|\n",
      "|     1.0|          4|   1.0|female|35.0|   53.1|       S|   1.0|    0.0|\n",
      "|     0.0|          5|   3.0|  male|35.0|   8.05|       S|   0.0|    0.0|\n",
      "|     0.0|          7|   1.0|  male|54.0|51.8625|       S|   0.0|    0.0|\n",
      "|     0.0|          8|   3.0|  male| 2.0| 21.075|       S|   0.0|    0.0|\n",
      "|     1.0|          9|   3.0|female|27.0|11.1333|       S|   1.0|    0.0|\n",
      "|     1.0|         10|   2.0|female|14.0|30.0708|       C|   1.0|    1.0|\n",
      "|     1.0|         11|   3.0|female| 4.0|   16.7|       S|   1.0|    0.0|\n",
      "|     1.0|         12|   1.0|female|58.0|  26.55|       S|   1.0|    0.0|\n",
      "|     0.0|         13|   3.0|  male|20.0|   8.05|       S|   0.0|    0.0|\n",
      "|     0.0|         14|   3.0|  male|39.0| 31.275|       S|   0.0|    0.0|\n",
      "|     0.0|         15|   3.0|female|14.0| 7.8542|       S|   1.0|    0.0|\n",
      "|     1.0|         16|   2.0|female|55.0|   16.0|       S|   1.0|    0.0|\n",
      "|     0.0|         17|   3.0|  male| 2.0| 29.125|       Q|   0.0|    2.0|\n",
      "|     0.0|         19|   3.0|female|31.0|   18.0|       S|   1.0|    0.0|\n",
      "|     0.0|         21|   2.0|  male|35.0|   26.0|       S|   0.0|    0.0|\n",
      "|     1.0|         22|   2.0|  male|34.0|   13.0|       S|   0.0|    0.0|\n",
      "|     1.0|         23|   3.0|female|15.0| 8.0292|       Q|   1.0|    2.0|\n",
      "+--------+-----------+------+------+----+-------+--------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+------+------+----+-------+--------+------+-------+\n",
      "|PassengerId|Pclass|   Sex| Age|   Fare|Embarked|Gender|Boarded|\n",
      "+-----------+------+------+----+-------+--------+------+-------+\n",
      "|        892|   3.0|  male|34.5| 7.8292|       Q|   0.0|    2.0|\n",
      "|        893|   3.0|female|47.0|    7.0|       S|   1.0|    0.0|\n",
      "|        894|   2.0|  male|62.0| 9.6875|       Q|   0.0|    2.0|\n",
      "|        895|   3.0|  male|27.0| 8.6625|       S|   0.0|    0.0|\n",
      "|        896|   3.0|female|22.0|12.2875|       S|   1.0|    0.0|\n",
      "|        897|   3.0|  male|14.0|  9.225|       S|   0.0|    0.0|\n",
      "|        898|   3.0|female|30.0| 7.6292|       Q|   1.0|    2.0|\n",
      "|        899|   2.0|  male|26.0|   29.0|       S|   0.0|    0.0|\n",
      "|        900|   3.0|female|18.0| 7.2292|       C|   1.0|    1.0|\n",
      "|        901|   3.0|  male|21.0|  24.15|       S|   0.0|    0.0|\n",
      "|        903|   1.0|  male|46.0|   26.0|       S|   0.0|    0.0|\n",
      "|        904|   1.0|female|23.0|82.2667|       S|   1.0|    0.0|\n",
      "|        905|   2.0|  male|63.0|   26.0|       S|   0.0|    0.0|\n",
      "|        906|   1.0|female|47.0| 61.175|       S|   1.0|    0.0|\n",
      "|        907|   2.0|female|24.0|27.7208|       C|   1.0|    1.0|\n",
      "|        908|   2.0|  male|35.0|  12.35|       Q|   0.0|    2.0|\n",
      "|        909|   3.0|  male|21.0|  7.225|       C|   0.0|    1.0|\n",
      "|        910|   3.0|female|27.0|  7.925|       S|   1.0|    0.0|\n",
      "|        911|   3.0|female|45.0|  7.225|       C|   1.0|    1.0|\n",
      "|        912|   1.0|  male|55.0|   59.4|       C|   0.0|    1.0|\n",
      "+-----------+------+------+----+-------+--------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark ML library only works with numeric data. \n",
    "# But we still want to use the Sex and the Embarked column. \n",
    "# For that, we will need to encode (transform) them. Sex -> Gender; Embarked -> Boarded\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer # todo: learn Spark ML API\n",
    "\n",
    "# for training ds\n",
    "training_ds = StringIndexer(\n",
    "    inputCol='Sex', \n",
    "    outputCol='Gender', \n",
    "    handleInvalid='keep').fit(training_ds).transform(training_ds)\n",
    "training_ds = StringIndexer(\n",
    "    inputCol='Embarked', \n",
    "    outputCol='Boarded', \n",
    "    handleInvalid='keep').fit(training_ds).transform(training_ds)\n",
    "\n",
    "# for test ds\n",
    "test_ds = StringIndexer(\n",
    "    inputCol='Sex', \n",
    "    outputCol='Gender', \n",
    "    handleInvalid='keep').fit(test_ds).transform(test_ds)\n",
    "test_ds = StringIndexer(\n",
    "    inputCol='Embarked', \n",
    "    outputCol='Boarded', \n",
    "    handleInvalid='keep').fit(test_ds).transform(test_ds)\n",
    "\n",
    "training_ds.show()\n",
    "test_ds.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Survived', 'float'),\n",
       " ('PassengerId', 'int'),\n",
       " ('Pclass', 'float'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'float'),\n",
       " ('Fare', 'float'),\n",
       " ('Embarked', 'string'),\n",
       " ('Gender', 'double'),\n",
       " ('Boarded', 'double')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PassengerId', 'int'),\n",
       " ('Pclass', 'float'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'float'),\n",
       " ('Fare', 'float'),\n",
       " ('Embarked', 'string'),\n",
       " ('Gender', 'double'),\n",
       " ('Boarded', 'double')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+----+-------+------+-------+\n",
      "|Survived|PassengerId|Pclass| Age|   Fare|Gender|Boarded|\n",
      "+--------+-----------+------+----+-------+------+-------+\n",
      "|     0.0|          1|   3.0|22.0|   7.25|   0.0|    0.0|\n",
      "|     1.0|          2|   1.0|38.0|71.2833|   1.0|    1.0|\n",
      "|     1.0|          3|   3.0|26.0|  7.925|   1.0|    0.0|\n",
      "|     1.0|          4|   1.0|35.0|   53.1|   1.0|    0.0|\n",
      "|     0.0|          5|   3.0|35.0|   8.05|   0.0|    0.0|\n",
      "|     0.0|          7|   1.0|54.0|51.8625|   0.0|    0.0|\n",
      "|     0.0|          8|   3.0| 2.0| 21.075|   0.0|    0.0|\n",
      "|     1.0|          9|   3.0|27.0|11.1333|   1.0|    0.0|\n",
      "|     1.0|         10|   2.0|14.0|30.0708|   1.0|    1.0|\n",
      "|     1.0|         11|   3.0| 4.0|   16.7|   1.0|    0.0|\n",
      "|     1.0|         12|   1.0|58.0|  26.55|   1.0|    0.0|\n",
      "|     0.0|         13|   3.0|20.0|   8.05|   0.0|    0.0|\n",
      "|     0.0|         14|   3.0|39.0| 31.275|   0.0|    0.0|\n",
      "|     0.0|         15|   3.0|14.0| 7.8542|   1.0|    0.0|\n",
      "|     1.0|         16|   2.0|55.0|   16.0|   1.0|    0.0|\n",
      "|     0.0|         17|   3.0| 2.0| 29.125|   0.0|    2.0|\n",
      "|     0.0|         19|   3.0|31.0|   18.0|   1.0|    0.0|\n",
      "|     0.0|         21|   2.0|35.0|   26.0|   0.0|    0.0|\n",
      "|     1.0|         22|   2.0|34.0|   13.0|   0.0|    0.0|\n",
      "|     1.0|         23|   3.0|15.0| 8.0292|   1.0|    2.0|\n",
      "+--------+-----------+------+----+-------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+------+----+-------+------+-------+\n",
      "|PassengerId|Pclass| Age|   Fare|Gender|Boarded|\n",
      "+-----------+------+----+-------+------+-------+\n",
      "|        892|   3.0|34.5| 7.8292|   0.0|    2.0|\n",
      "|        893|   3.0|47.0|    7.0|   1.0|    0.0|\n",
      "|        894|   2.0|62.0| 9.6875|   0.0|    2.0|\n",
      "|        895|   3.0|27.0| 8.6625|   0.0|    0.0|\n",
      "|        896|   3.0|22.0|12.2875|   1.0|    0.0|\n",
      "|        897|   3.0|14.0|  9.225|   0.0|    0.0|\n",
      "|        898|   3.0|30.0| 7.6292|   1.0|    2.0|\n",
      "|        899|   2.0|26.0|   29.0|   0.0|    0.0|\n",
      "|        900|   3.0|18.0| 7.2292|   1.0|    1.0|\n",
      "|        901|   3.0|21.0|  24.15|   0.0|    0.0|\n",
      "|        903|   1.0|46.0|   26.0|   0.0|    0.0|\n",
      "|        904|   1.0|23.0|82.2667|   1.0|    0.0|\n",
      "|        905|   2.0|63.0|   26.0|   0.0|    0.0|\n",
      "|        906|   1.0|47.0| 61.175|   1.0|    0.0|\n",
      "|        907|   2.0|24.0|27.7208|   1.0|    1.0|\n",
      "|        908|   2.0|35.0|  12.35|   0.0|    2.0|\n",
      "|        909|   3.0|21.0|  7.225|   0.0|    1.0|\n",
      "|        910|   3.0|27.0|  7.925|   1.0|    0.0|\n",
      "|        911|   3.0|45.0|  7.225|   1.0|    1.0|\n",
      "|        912|   1.0|55.0|   59.4|   0.0|    1.0|\n",
      "+-----------+------+----+-------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns from training ds\n",
    "training_ds = training_ds.drop('Sex')\n",
    "training_ds = training_ds.drop('Embarked')\n",
    "training_ds.show()\n",
    "\n",
    "# Drop unnecessary columns from test ds\n",
    "test_ds = test_ds.drop('Sex')\n",
    "test_ds = test_ds.drop('Embarked')\n",
    "test_ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Pclass: float, Age: float, Fare: float, Gender: double, Boarded: double, features: vector]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark works to predict with a column with all the features smashed together into a list-like structure.\n",
    "# I want to predict “Survived”, I need to combine the information other columns into one column.\n",
    "# That column is called \"features\" and it's value should look like say [3.0, 22.0, 7.25, 0, 0]\n",
    "\n",
    "# Assemble all the features with VectorAssembler\n",
    "required_features = [\n",
    "                    'Pclass',\n",
    "                    'Age',\n",
    "                    'Fare',\n",
    "                    'Gender',\n",
    "                    'Boarded'\n",
    "                   ]\n",
    "from pyspark.ml.feature import VectorAssembler # todo\n",
    "assembler = VectorAssembler(inputCols=required_features, outputCol='features')\n",
    "transformed_training_data = assembler.transform(training_ds)\n",
    "transformed_test_data = assembler.transform(test_ds)\n",
    "\n",
    "transformed_training_data\n",
    "transformed_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+----+-------+------+-------+--------------------+\n",
      "|Survived|PassengerId|Pclass| Age|   Fare|Gender|Boarded|            features|\n",
      "+--------+-----------+------+----+-------+------+-------+--------------------+\n",
      "|     0.0|          1|   3.0|22.0|   7.25|   0.0|    0.0|[3.0,22.0,7.25,0....|\n",
      "|     1.0|          2|   1.0|38.0|71.2833|   1.0|    1.0|[1.0,38.0,71.2833...|\n",
      "|     1.0|          3|   3.0|26.0|  7.925|   1.0|    0.0|[3.0,26.0,7.92500...|\n",
      "|     1.0|          4|   1.0|35.0|   53.1|   1.0|    0.0|[1.0,35.0,53.0999...|\n",
      "|     0.0|          5|   3.0|35.0|   8.05|   0.0|    0.0|[3.0,35.0,8.05000...|\n",
      "|     0.0|          7|   1.0|54.0|51.8625|   0.0|    0.0|[1.0,54.0,51.8624...|\n",
      "|     0.0|          8|   3.0| 2.0| 21.075|   0.0|    0.0|[3.0,2.0,21.07500...|\n",
      "|     1.0|          9|   3.0|27.0|11.1333|   1.0|    0.0|[3.0,27.0,11.1332...|\n",
      "|     1.0|         10|   2.0|14.0|30.0708|   1.0|    1.0|[2.0,14.0,30.0708...|\n",
      "|     1.0|         11|   3.0| 4.0|   16.7|   1.0|    0.0|[3.0,4.0,16.70000...|\n",
      "|     1.0|         12|   1.0|58.0|  26.55|   1.0|    0.0|[1.0,58.0,26.5499...|\n",
      "|     0.0|         13|   3.0|20.0|   8.05|   0.0|    0.0|[3.0,20.0,8.05000...|\n",
      "|     0.0|         14|   3.0|39.0| 31.275|   0.0|    0.0|[3.0,39.0,31.2749...|\n",
      "|     0.0|         15|   3.0|14.0| 7.8542|   1.0|    0.0|[3.0,14.0,7.85419...|\n",
      "|     1.0|         16|   2.0|55.0|   16.0|   1.0|    0.0|[2.0,55.0,16.0,1....|\n",
      "|     0.0|         17|   3.0| 2.0| 29.125|   0.0|    2.0|[3.0,2.0,29.125,0...|\n",
      "|     0.0|         19|   3.0|31.0|   18.0|   1.0|    0.0|[3.0,31.0,18.0,1....|\n",
      "|     0.0|         21|   2.0|35.0|   26.0|   0.0|    0.0|[2.0,35.0,26.0,0....|\n",
      "|     1.0|         22|   2.0|34.0|   13.0|   0.0|    0.0|[2.0,34.0,13.0,0....|\n",
      "|     1.0|         23|   3.0|15.0| 8.0292|   1.0|    2.0|[3.0,15.0,8.02919...|\n",
      "+--------+-----------+------+----+-------+------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+------+----+-------+------+-------+--------------------+\n",
      "|PassengerId|Pclass| Age|   Fare|Gender|Boarded|            features|\n",
      "+-----------+------+----+-------+------+-------+--------------------+\n",
      "|        892|   3.0|34.5| 7.8292|   0.0|    2.0|[3.0,34.5,7.82919...|\n",
      "|        893|   3.0|47.0|    7.0|   1.0|    0.0|[3.0,47.0,7.0,1.0...|\n",
      "|        894|   2.0|62.0| 9.6875|   0.0|    2.0|[2.0,62.0,9.6875,...|\n",
      "|        895|   3.0|27.0| 8.6625|   0.0|    0.0|[3.0,27.0,8.66250...|\n",
      "|        896|   3.0|22.0|12.2875|   1.0|    0.0|[3.0,22.0,12.2875...|\n",
      "|        897|   3.0|14.0|  9.225|   0.0|    0.0|[3.0,14.0,9.22500...|\n",
      "|        898|   3.0|30.0| 7.6292|   1.0|    2.0|[3.0,30.0,7.62919...|\n",
      "|        899|   2.0|26.0|   29.0|   0.0|    0.0|[2.0,26.0,29.0,0....|\n",
      "|        900|   3.0|18.0| 7.2292|   1.0|    1.0|[3.0,18.0,7.22919...|\n",
      "|        901|   3.0|21.0|  24.15|   0.0|    0.0|[3.0,21.0,24.1499...|\n",
      "|        903|   1.0|46.0|   26.0|   0.0|    0.0|[1.0,46.0,26.0,0....|\n",
      "|        904|   1.0|23.0|82.2667|   1.0|    0.0|[1.0,23.0,82.2667...|\n",
      "|        905|   2.0|63.0|   26.0|   0.0|    0.0|[2.0,63.0,26.0,0....|\n",
      "|        906|   1.0|47.0| 61.175|   1.0|    0.0|[1.0,47.0,61.1749...|\n",
      "|        907|   2.0|24.0|27.7208|   1.0|    1.0|[2.0,24.0,27.7208...|\n",
      "|        908|   2.0|35.0|  12.35|   0.0|    2.0|[2.0,35.0,12.3500...|\n",
      "|        909|   3.0|21.0|  7.225|   0.0|    1.0|[3.0,21.0,7.22499...|\n",
      "|        910|   3.0|27.0|  7.925|   1.0|    0.0|[3.0,27.0,7.92500...|\n",
      "|        911|   3.0|45.0|  7.225|   1.0|    1.0|[3.0,45.0,7.22499...|\n",
      "|        912|   1.0|55.0|   59.4|   0.0|    1.0|[1.0,55.0,59.4000...|\n",
      "+-----------+------+----+-------+------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_training_data.show()\n",
    "transformed_test_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point our data prep is done\n",
    "# We will start Modeling now..\n",
    "\n",
    "# As we have seperate training and testing data, we will use that as it is!\n",
    "training_data = transformed_training_data\n",
    "test_data = transformed_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and fit an ML model to our dataset to predict the “Survived” columns with all the other ones. \n",
    "# We will be using a Random Forest Classifier. This is actually an estimator that we have to fit.\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier # todo\n",
    "rf = RandomForestClassifier(labelCol='Survived', \n",
    "                            featuresCol='features',\n",
    "                            maxDepth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel (uid=RandomForestClassifier_2e9cd9294e6d) with 20 trees"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we fit (train) the model with training data\n",
    "model = rf.fit(training_data)\n",
    "\n",
    "# This will give us something called a transformer.\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Pclass: float, Age: float, Fare: float, Gender: double, Boarded: double, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And finally, we predict using the test dataset\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----+-------+------+-------+--------------------+--------------------+--------------------+----------+\n",
      "|PassengerId|Pclass| Age|   Fare|Gender|Boarded|            features|       rawPrediction|         probability|prediction|\n",
      "+-----------+------+----+-------+------+-------+--------------------+--------------------+--------------------+----------+\n",
      "|        892|   3.0|34.5| 7.8292|   0.0|    2.0|[3.0,34.5,7.82919...|[17.8640001490272...|[0.89320000745136...|       0.0|\n",
      "|        893|   3.0|47.0|    7.0|   1.0|    0.0|[3.0,47.0,7.0,1.0...|[14.5042162887630...|[0.72521081443815...|       0.0|\n",
      "|        894|   2.0|62.0| 9.6875|   0.0|    2.0|[2.0,62.0,9.6875,...|[17.3879108600806...|[0.86939554300403...|       0.0|\n",
      "|        895|   3.0|27.0| 8.6625|   0.0|    0.0|[3.0,27.0,8.66250...|[17.4542819747024...|[0.87271409873512...|       0.0|\n",
      "|        896|   3.0|22.0|12.2875|   1.0|    0.0|[3.0,22.0,12.2875...|[9.60722572247785...|[0.48036128612389...|       1.0|\n",
      "|        897|   3.0|14.0|  9.225|   0.0|    0.0|[3.0,14.0,9.22500...|[12.9698137196043...|[0.64849068598021...|       0.0|\n",
      "|        898|   3.0|30.0| 7.6292|   1.0|    2.0|[3.0,30.0,7.62919...|[13.8699234218094...|[0.69349617109047...|       0.0|\n",
      "|        899|   2.0|26.0|   29.0|   0.0|    0.0|[2.0,26.0,29.0,0....|[16.7166282680188...|[0.83583141340094...|       0.0|\n",
      "|        900|   3.0|18.0| 7.2292|   1.0|    1.0|[3.0,18.0,7.22919...|[6.70885521396381...|[0.33544276069819...|       1.0|\n",
      "|        901|   3.0|21.0|  24.15|   0.0|    0.0|[3.0,21.0,24.1499...|[17.1595293176711...|[0.85797646588355...|       0.0|\n",
      "|        903|   1.0|46.0|   26.0|   0.0|    0.0|[1.0,46.0,26.0,0....|[15.1919040157004...|[0.75959520078502...|       0.0|\n",
      "|        904|   1.0|23.0|82.2667|   1.0|    0.0|[1.0,23.0,82.2667...|[0.58754624637176...|[0.02937731231858...|       1.0|\n",
      "|        905|   2.0|63.0|   26.0|   0.0|    0.0|[2.0,63.0,26.0,0....|[16.4751215917396...|[0.82375607958697...|       0.0|\n",
      "|        906|   1.0|47.0| 61.175|   1.0|    0.0|[1.0,47.0,61.1749...|[0.85536412739485...|[0.04276820636974...|       1.0|\n",
      "|        907|   2.0|24.0|27.7208|   1.0|    1.0|[2.0,24.0,27.7208...|[1.45577517723539...|[0.07278875886176...|       1.0|\n",
      "|        908|   2.0|35.0|  12.35|   0.0|    2.0|[2.0,35.0,12.3500...|[17.9053683423987...|[0.89526841711993...|       0.0|\n",
      "|        909|   3.0|21.0|  7.225|   0.0|    1.0|[3.0,21.0,7.22499...|[17.2863194018815...|[0.86431597009407...|       0.0|\n",
      "|        910|   3.0|27.0|  7.925|   1.0|    0.0|[3.0,27.0,7.92500...|[9.08890952121354...|[0.45444547606067...|       1.0|\n",
      "|        911|   3.0|45.0|  7.225|   1.0|    1.0|[3.0,45.0,7.22499...|[14.1267713124809...|[0.70633856562404...|       0.0|\n",
      "|        912|   1.0|55.0|   59.4|   0.0|    1.0|[1.0,55.0,59.4000...|[14.3945596326435...|[0.71972798163217...|       0.0|\n",
      "+-----------+------+----+-------+------+-------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Done! My first Spark ML model\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|PassengerId|Survived|\n",
      "+-----------+--------+\n",
      "|        892|       0|\n",
      "|        893|       0|\n",
      "|        894|       0|\n",
      "|        895|       0|\n",
      "|        896|       1|\n",
      "|        897|       0|\n",
      "|        898|       0|\n",
      "|        899|       0|\n",
      "|        900|       1|\n",
      "|        901|       0|\n",
      "|        903|       0|\n",
      "|        904|       1|\n",
      "|        905|       0|\n",
      "|        906|       1|\n",
      "|        907|       1|\n",
      "|        908|       0|\n",
      "|        909|       0|\n",
      "|        910|       1|\n",
      "|        911|       0|\n",
      "|        912|       0|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finally saving the prediction to a local folder\n",
    "\n",
    "output_predictions = predictions.select(col('PassengerId').cast('int'),\n",
    "                                        col('prediction').cast('int').alias('Survived')\n",
    "                                       )\n",
    "\n",
    "output_predictions.show()\n",
    "\n",
    "output_predictions.write.format('csv').option('header', True).mode('overwrite').option('sep',',').save('./output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the prediction to https://www.kaggle.com/c/titanic/submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
