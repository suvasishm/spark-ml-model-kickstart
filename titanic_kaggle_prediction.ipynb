{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.53:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1178054a8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data into Spark using DataFrames\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Titanic Data').getOrCreate()\n",
    "\n",
    "spark # prints what's in the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Survived: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the training data and create a DataFrames\n",
    "training_df = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"./data/train.csv\"))\n",
    "\n",
    "training_df # prints the DF structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|   4|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|  58|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|  20|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|  39|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|  14|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|  55|    0|    0|          248706|     16| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|   2|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|     13| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|  31|    1|    0|          345763|     18| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print some training data records and count from the DF\n",
    "training_df.show()\n",
    "training_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test data and create a DataFrames\n",
    "test_df = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"./data/test.csv\"))\n",
    "\n",
    "test_df # prints the DF structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0|          330911| 7.8292| null|       Q|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|  47|    1|    0|          363272|      7| null|       S|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|  62|    0|    0|          240276| 9.6875| null|       Q|\n",
      "|        895|     3|    Wirz, Mr. Albert|  male|  27|    0|    0|          315154| 8.6625| null|       S|\n",
      "|        896|     3|Hirvonen, Mrs. Al...|female|  22|    1|    1|         3101298|12.2875| null|       S|\n",
      "|        897|     3|Svensson, Mr. Joh...|  male|  14|    0|    0|            7538|  9.225| null|       S|\n",
      "|        898|     3|Connolly, Miss. Kate|female|  30|    0|    0|          330972| 7.6292| null|       Q|\n",
      "|        899|     2|Caldwell, Mr. Alb...|  male|  26|    1|    1|          248738|     29| null|       S|\n",
      "|        900|     3|Abrahim, Mrs. Jos...|female|  18|    0|    0|            2657| 7.2292| null|       C|\n",
      "|        901|     3|Davies, Mr. John ...|  male|  21|    2|    0|       A/4 48871|  24.15| null|       S|\n",
      "|        902|     3|    Ilieff, Mr. Ylio|  male|null|    0|    0|          349220| 7.8958| null|       S|\n",
      "|        903|     1|Jones, Mr. Charle...|  male|  46|    0|    0|             694|     26| null|       S|\n",
      "|        904|     1|Snyder, Mrs. John...|female|  23|    1|    0|           21228|82.2667|  B45|       S|\n",
      "|        905|     2|Howard, Mr. Benjamin|  male|  63|    1|    0|           24065|     26| null|       S|\n",
      "|        906|     1|Chaffee, Mrs. Her...|female|  47|    1|    0|     W.E.P. 5734| 61.175|  E31|       S|\n",
      "|        907|     2|del Carlo, Mrs. S...|female|  24|    1|    0|   SC/PARIS 2167|27.7208| null|       C|\n",
      "|        908|     2|   Keane, Mr. Daniel|  male|  35|    0|    0|          233734|  12.35| null|       Q|\n",
      "|        909|     3|   Assaf, Mr. Gerios|  male|  21|    0|    0|            2692|  7.225| null|       C|\n",
      "|        910|     3|Ilmakangas, Miss....|female|  27|    1|    0|STON/O2. 3101270|  7.925| null|       S|\n",
      "|        911|     3|\"Assaf Khalil, Mr...|female|  45|    0|    0|            2696|  7.225| null|       C|\n",
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print some test data records and count from the DF\n",
    "\n",
    "test_df.show()\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+------+----+-------+--------+\n",
      "|Survived|PassengerId|Pclass|   Sex| Age|   Fare|Embarked|\n",
      "+--------+-----------+------+------+----+-------+--------+\n",
      "|     0.0|          1|   3.0|  male|22.0|   7.25|       S|\n",
      "|     1.0|          2|   1.0|female|38.0|71.2833|       C|\n",
      "|     1.0|          3|   3.0|female|26.0|  7.925|       S|\n",
      "|     1.0|          4|   1.0|female|35.0|   53.1|       S|\n",
      "|     0.0|          5|   3.0|  male|35.0|   8.05|       S|\n",
      "|     0.0|          6|   3.0|  male|null| 8.4583|       Q|\n",
      "|     0.0|          7|   1.0|  male|54.0|51.8625|       S|\n",
      "|     0.0|          8|   3.0|  male| 2.0| 21.075|       S|\n",
      "|     1.0|          9|   3.0|female|27.0|11.1333|       S|\n",
      "|     1.0|         10|   2.0|female|14.0|30.0708|       C|\n",
      "|     1.0|         11|   3.0|female| 4.0|   16.7|       S|\n",
      "|     1.0|         12|   1.0|female|58.0|  26.55|       S|\n",
      "|     0.0|         13|   3.0|  male|20.0|   8.05|       S|\n",
      "|     0.0|         14|   3.0|  male|39.0| 31.275|       S|\n",
      "|     0.0|         15|   3.0|female|14.0| 7.8542|       S|\n",
      "|     1.0|         16|   2.0|female|55.0|   16.0|       S|\n",
      "|     0.0|         17|   3.0|  male| 2.0| 29.125|       Q|\n",
      "|     1.0|         18|   2.0|  male|null|   13.0|       S|\n",
      "|     0.0|         19|   3.0|female|31.0|   18.0|       S|\n",
      "|     1.0|         20|   3.0|female|null|  7.225|       C|\n",
      "+--------+-----------+------+------+----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start Data prep!\n",
    "\n",
    "# Prepare a training dataset by casting some of columns to required type!\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "training_ds = training_df.select(col('Survived').cast('float'),\n",
    "                                 col('PassengerId').cast('int'),\n",
    "                                 col('Pclass').cast('float'),\n",
    "                                 col('Sex'),\n",
    "                                 col('Age').cast('float'),\n",
    "                                 col('Fare').cast('float'),\n",
    "                                 col('Embarked')\n",
    "                                )\n",
    "training_ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+----+-------+--------+\n",
      "|PassengerId|Pclass|   Sex| Age|   Fare|Embarked|\n",
      "+-----------+------+------+----+-------+--------+\n",
      "|        892|   3.0|  male|34.5| 7.8292|       Q|\n",
      "|        893|   3.0|female|47.0|    7.0|       S|\n",
      "|        894|   2.0|  male|62.0| 9.6875|       Q|\n",
      "|        895|   3.0|  male|27.0| 8.6625|       S|\n",
      "|        896|   3.0|female|22.0|12.2875|       S|\n",
      "|        897|   3.0|  male|14.0|  9.225|       S|\n",
      "|        898|   3.0|female|30.0| 7.6292|       Q|\n",
      "|        899|   2.0|  male|26.0|   29.0|       S|\n",
      "|        900|   3.0|female|18.0| 7.2292|       C|\n",
      "|        901|   3.0|  male|21.0|  24.15|       S|\n",
      "|        902|   3.0|  male|null| 7.8958|       S|\n",
      "|        903|   1.0|  male|46.0|   26.0|       S|\n",
      "|        904|   1.0|female|23.0|82.2667|       S|\n",
      "|        905|   2.0|  male|63.0|   26.0|       S|\n",
      "|        906|   1.0|female|47.0| 61.175|       S|\n",
      "|        907|   2.0|female|24.0|27.7208|       C|\n",
      "|        908|   2.0|  male|35.0|  12.35|       Q|\n",
      "|        909|   3.0|  male|21.0|  7.225|       C|\n",
      "|        910|   3.0|female|27.0|  7.925|       S|\n",
      "|        911|   3.0|female|45.0|  7.225|       C|\n",
      "+-----------+------+------+----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare a test dataset by casting some of columns to required type!\n",
    "test_ds = test_df.select(\n",
    "                         col('PassengerId').cast('int'),\n",
    "                         col('Pclass').cast('float'),\n",
    "                         col('Sex'),\n",
    "                         col('Age').cast('float'),\n",
    "                         col('Fare').cast('float'),\n",
    "                         col('Embarked')\n",
    "                        )\n",
    "test_ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+---+---+----+--------+\n",
      "|Survived|PassengerId|Pclass|Sex|Age|Fare|Embarked|\n",
      "+--------+-----------+------+---+---+----+--------+\n",
      "|       0|          0|     0|  0|177|   0|       2|\n",
      "+--------+-----------+------+---+---+----+--------+\n",
      "\n",
      "+-----------+------+---+---+----+--------+\n",
      "|PassengerId|Pclass|Sex|Age|Fare|Embarked|\n",
      "+-----------+------+---+---+----+--------+\n",
      "|          0|     0|  0| 86|   1|       0|\n",
      "+-----------+------+---+---+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "training_ds.select([count(when(isnull(c), c)).alias(c) for c in training_ds.columns]).show() # todo: learn to query\n",
    "test_ds.select([count(when(isnull(c), c)).alias(c) for c in test_ds.columns]).show() # todo: learn to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+------+----+-------+--------+\n",
      "|Survived|PassengerId|Pclass|   Sex| Age|   Fare|Embarked|\n",
      "+--------+-----------+------+------+----+-------+--------+\n",
      "|     0.0|          1|   3.0|  male|22.0|   7.25|       S|\n",
      "|     1.0|          2|   1.0|female|38.0|71.2833|       C|\n",
      "|     1.0|          3|   3.0|female|26.0|  7.925|       S|\n",
      "|     1.0|          4|   1.0|female|35.0|   53.1|       S|\n",
      "|     0.0|          5|   3.0|  male|35.0|   8.05|       S|\n",
      "|     0.0|          6|   3.0|  male| 0.0| 8.4583|       Q|\n",
      "|     0.0|          7|   1.0|  male|54.0|51.8625|       S|\n",
      "|     0.0|          8|   3.0|  male| 2.0| 21.075|       S|\n",
      "|     1.0|          9|   3.0|female|27.0|11.1333|       S|\n",
      "|     1.0|         10|   2.0|female|14.0|30.0708|       C|\n",
      "|     1.0|         11|   3.0|female| 4.0|   16.7|       S|\n",
      "|     1.0|         12|   1.0|female|58.0|  26.55|       S|\n",
      "|     0.0|         13|   3.0|  male|20.0|   8.05|       S|\n",
      "|     0.0|         14|   3.0|  male|39.0| 31.275|       S|\n",
      "|     0.0|         15|   3.0|female|14.0| 7.8542|       S|\n",
      "|     1.0|         16|   2.0|female|55.0|   16.0|       S|\n",
      "|     0.0|         17|   3.0|  male| 2.0| 29.125|       Q|\n",
      "|     1.0|         18|   2.0|  male| 0.0|   13.0|       S|\n",
      "|     0.0|         19|   3.0|female|31.0|   18.0|       S|\n",
      "|     1.0|         20|   3.0|female| 0.0|  7.225|       C|\n",
      "+--------+-----------+------+------+----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminate rows with null values in columns from the training dataset\n",
    "# training_ds = training_ds.replace('?', None).dropna(how='any') # todo: learn the Dataset API\n",
    "\n",
    "# Replacing null values with 0\n",
    "training_ds = training_ds.na.fill(0)\n",
    "test_ds = test_ds.na.fill(0)\n",
    "\n",
    "training_ds.show()\n",
    "training_ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+------+----+-------+--------+------+-------+\n",
      "|Survived|PassengerId|Pclass|   Sex| Age|   Fare|Embarked|Gender|Boarded|\n",
      "+--------+-----------+------+------+----+-------+--------+------+-------+\n",
      "|     0.0|          1|   3.0|  male|22.0|   7.25|       S|   0.0|    0.0|\n",
      "|     1.0|          2|   1.0|female|38.0|71.2833|       C|   1.0|    1.0|\n",
      "|     1.0|          3|   3.0|female|26.0|  7.925|       S|   1.0|    0.0|\n",
      "|     1.0|          4|   1.0|female|35.0|   53.1|       S|   1.0|    0.0|\n",
      "|     0.0|          5|   3.0|  male|35.0|   8.05|       S|   0.0|    0.0|\n",
      "|     0.0|          6|   3.0|  male| 0.0| 8.4583|       Q|   0.0|    2.0|\n",
      "|     0.0|          7|   1.0|  male|54.0|51.8625|       S|   0.0|    0.0|\n",
      "|     0.0|          8|   3.0|  male| 2.0| 21.075|       S|   0.0|    0.0|\n",
      "|     1.0|          9|   3.0|female|27.0|11.1333|       S|   1.0|    0.0|\n",
      "|     1.0|         10|   2.0|female|14.0|30.0708|       C|   1.0|    1.0|\n",
      "|     1.0|         11|   3.0|female| 4.0|   16.7|       S|   1.0|    0.0|\n",
      "|     1.0|         12|   1.0|female|58.0|  26.55|       S|   1.0|    0.0|\n",
      "|     0.0|         13|   3.0|  male|20.0|   8.05|       S|   0.0|    0.0|\n",
      "|     0.0|         14|   3.0|  male|39.0| 31.275|       S|   0.0|    0.0|\n",
      "|     0.0|         15|   3.0|female|14.0| 7.8542|       S|   1.0|    0.0|\n",
      "|     1.0|         16|   2.0|female|55.0|   16.0|       S|   1.0|    0.0|\n",
      "|     0.0|         17|   3.0|  male| 2.0| 29.125|       Q|   0.0|    2.0|\n",
      "|     1.0|         18|   2.0|  male| 0.0|   13.0|       S|   0.0|    0.0|\n",
      "|     0.0|         19|   3.0|female|31.0|   18.0|       S|   1.0|    0.0|\n",
      "|     1.0|         20|   3.0|female| 0.0|  7.225|       C|   1.0|    1.0|\n",
      "+--------+-----------+------+------+----+-------+--------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+------+------+----+-------+--------+------+-------+\n",
      "|PassengerId|Pclass|   Sex| Age|   Fare|Embarked|Gender|Boarded|\n",
      "+-----------+------+------+----+-------+--------+------+-------+\n",
      "|        892|   3.0|  male|34.5| 7.8292|       Q|   0.0|    2.0|\n",
      "|        893|   3.0|female|47.0|    7.0|       S|   1.0|    0.0|\n",
      "|        894|   2.0|  male|62.0| 9.6875|       Q|   0.0|    2.0|\n",
      "|        895|   3.0|  male|27.0| 8.6625|       S|   0.0|    0.0|\n",
      "|        896|   3.0|female|22.0|12.2875|       S|   1.0|    0.0|\n",
      "|        897|   3.0|  male|14.0|  9.225|       S|   0.0|    0.0|\n",
      "|        898|   3.0|female|30.0| 7.6292|       Q|   1.0|    2.0|\n",
      "|        899|   2.0|  male|26.0|   29.0|       S|   0.0|    0.0|\n",
      "|        900|   3.0|female|18.0| 7.2292|       C|   1.0|    1.0|\n",
      "|        901|   3.0|  male|21.0|  24.15|       S|   0.0|    0.0|\n",
      "|        902|   3.0|  male| 0.0| 7.8958|       S|   0.0|    0.0|\n",
      "|        903|   1.0|  male|46.0|   26.0|       S|   0.0|    0.0|\n",
      "|        904|   1.0|female|23.0|82.2667|       S|   1.0|    0.0|\n",
      "|        905|   2.0|  male|63.0|   26.0|       S|   0.0|    0.0|\n",
      "|        906|   1.0|female|47.0| 61.175|       S|   1.0|    0.0|\n",
      "|        907|   2.0|female|24.0|27.7208|       C|   1.0|    1.0|\n",
      "|        908|   2.0|  male|35.0|  12.35|       Q|   0.0|    2.0|\n",
      "|        909|   3.0|  male|21.0|  7.225|       C|   0.0|    1.0|\n",
      "|        910|   3.0|female|27.0|  7.925|       S|   1.0|    0.0|\n",
      "|        911|   3.0|female|45.0|  7.225|       C|   1.0|    1.0|\n",
      "+-----------+------+------+----+-------+--------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark ML library only works with numeric data. \n",
    "# But we still want to use the Sex and the Embarked column. \n",
    "# For that, we will need to encode (transform) them. Sex -> Gender; Embarked -> Boarded\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer # todo: learn Spark ML API\n",
    "\n",
    "# for training ds\n",
    "training_ds = StringIndexer(\n",
    "    inputCol='Sex', \n",
    "    outputCol='Gender', \n",
    "    handleInvalid='keep').fit(training_ds).transform(training_ds)\n",
    "training_ds = StringIndexer(\n",
    "    inputCol='Embarked', \n",
    "    outputCol='Boarded', \n",
    "    handleInvalid='keep').fit(training_ds).transform(training_ds)\n",
    "\n",
    "# for test ds\n",
    "test_ds = StringIndexer(\n",
    "    inputCol='Sex', \n",
    "    outputCol='Gender', \n",
    "    handleInvalid='skip').fit(test_ds).transform(test_ds)\n",
    "test_ds = StringIndexer(\n",
    "    inputCol='Embarked', \n",
    "    outputCol='Boarded', \n",
    "    handleInvalid='keep').fit(test_ds).transform(test_ds)\n",
    "\n",
    "training_ds.show()\n",
    "test_ds.show()\n",
    "test_ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Survived', 'float'),\n",
       " ('PassengerId', 'int'),\n",
       " ('Pclass', 'float'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'float'),\n",
       " ('Fare', 'float'),\n",
       " ('Embarked', 'string'),\n",
       " ('Gender', 'double'),\n",
       " ('Boarded', 'double')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PassengerId', 'int'),\n",
       " ('Pclass', 'float'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'float'),\n",
       " ('Fare', 'float'),\n",
       " ('Embarked', 'string'),\n",
       " ('Gender', 'double'),\n",
       " ('Boarded', 'double')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+----+-------+------+-------+\n",
      "|Survived|PassengerId|Pclass| Age|   Fare|Gender|Boarded|\n",
      "+--------+-----------+------+----+-------+------+-------+\n",
      "|     0.0|          1|   3.0|22.0|   7.25|   0.0|    0.0|\n",
      "|     1.0|          2|   1.0|38.0|71.2833|   1.0|    1.0|\n",
      "|     1.0|          3|   3.0|26.0|  7.925|   1.0|    0.0|\n",
      "|     1.0|          4|   1.0|35.0|   53.1|   1.0|    0.0|\n",
      "|     0.0|          5|   3.0|35.0|   8.05|   0.0|    0.0|\n",
      "|     0.0|          6|   3.0| 0.0| 8.4583|   0.0|    2.0|\n",
      "|     0.0|          7|   1.0|54.0|51.8625|   0.0|    0.0|\n",
      "|     0.0|          8|   3.0| 2.0| 21.075|   0.0|    0.0|\n",
      "|     1.0|          9|   3.0|27.0|11.1333|   1.0|    0.0|\n",
      "|     1.0|         10|   2.0|14.0|30.0708|   1.0|    1.0|\n",
      "|     1.0|         11|   3.0| 4.0|   16.7|   1.0|    0.0|\n",
      "|     1.0|         12|   1.0|58.0|  26.55|   1.0|    0.0|\n",
      "|     0.0|         13|   3.0|20.0|   8.05|   0.0|    0.0|\n",
      "|     0.0|         14|   3.0|39.0| 31.275|   0.0|    0.0|\n",
      "|     0.0|         15|   3.0|14.0| 7.8542|   1.0|    0.0|\n",
      "|     1.0|         16|   2.0|55.0|   16.0|   1.0|    0.0|\n",
      "|     0.0|         17|   3.0| 2.0| 29.125|   0.0|    2.0|\n",
      "|     1.0|         18|   2.0| 0.0|   13.0|   0.0|    0.0|\n",
      "|     0.0|         19|   3.0|31.0|   18.0|   1.0|    0.0|\n",
      "|     1.0|         20|   3.0| 0.0|  7.225|   1.0|    1.0|\n",
      "+--------+-----------+------+----+-------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+------+----+-------+------+-------+\n",
      "|PassengerId|Pclass| Age|   Fare|Gender|Boarded|\n",
      "+-----------+------+----+-------+------+-------+\n",
      "|        892|   3.0|34.5| 7.8292|   0.0|    2.0|\n",
      "|        893|   3.0|47.0|    7.0|   1.0|    0.0|\n",
      "|        894|   2.0|62.0| 9.6875|   0.0|    2.0|\n",
      "|        895|   3.0|27.0| 8.6625|   0.0|    0.0|\n",
      "|        896|   3.0|22.0|12.2875|   1.0|    0.0|\n",
      "|        897|   3.0|14.0|  9.225|   0.0|    0.0|\n",
      "|        898|   3.0|30.0| 7.6292|   1.0|    2.0|\n",
      "|        899|   2.0|26.0|   29.0|   0.0|    0.0|\n",
      "|        900|   3.0|18.0| 7.2292|   1.0|    1.0|\n",
      "|        901|   3.0|21.0|  24.15|   0.0|    0.0|\n",
      "|        902|   3.0| 0.0| 7.8958|   0.0|    0.0|\n",
      "|        903|   1.0|46.0|   26.0|   0.0|    0.0|\n",
      "|        904|   1.0|23.0|82.2667|   1.0|    0.0|\n",
      "|        905|   2.0|63.0|   26.0|   0.0|    0.0|\n",
      "|        906|   1.0|47.0| 61.175|   1.0|    0.0|\n",
      "|        907|   2.0|24.0|27.7208|   1.0|    1.0|\n",
      "|        908|   2.0|35.0|  12.35|   0.0|    2.0|\n",
      "|        909|   3.0|21.0|  7.225|   0.0|    1.0|\n",
      "|        910|   3.0|27.0|  7.925|   1.0|    0.0|\n",
      "|        911|   3.0|45.0|  7.225|   1.0|    1.0|\n",
      "+-----------+------+----+-------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns from training ds\n",
    "training_ds = training_ds.drop('Sex')\n",
    "training_ds = training_ds.drop('Embarked')\n",
    "training_ds.show()\n",
    "\n",
    "# Drop unnecessary columns from test ds\n",
    "test_ds = test_ds.drop('Sex')\n",
    "test_ds = test_ds.drop('Embarked')\n",
    "test_ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Pclass: float, Age: float, Fare: float, Gender: double, Boarded: double, features: vector]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark works to predict with a column with all the features smashed together into a list-like structure.\n",
    "# I want to predict “Survived”, I need to combine the information other columns into one column.\n",
    "# That column is called \"features\" and it's value should look like say [3.0, 22.0, 7.25, 0, 0]\n",
    "\n",
    "# Assemble all the features with VectorAssembler\n",
    "required_features = [\n",
    "                    'Pclass',\n",
    "                    'Age',\n",
    "                    'Fare',\n",
    "                    'Gender',\n",
    "                    'Boarded'\n",
    "                   ]\n",
    "from pyspark.ml.feature import VectorAssembler # todo\n",
    "assembler = VectorAssembler(inputCols=required_features, outputCol='features')\n",
    "\n",
    "transformed_training_data = assembler.transform(training_ds)\n",
    "transformed_test_data = assembler.transform(test_ds)\n",
    "\n",
    "transformed_training_data\n",
    "transformed_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+----+-------+------+-------+--------------------+\n",
      "|Survived|PassengerId|Pclass| Age|   Fare|Gender|Boarded|            features|\n",
      "+--------+-----------+------+----+-------+------+-------+--------------------+\n",
      "|     0.0|          1|   3.0|22.0|   7.25|   0.0|    0.0|[3.0,22.0,7.25,0....|\n",
      "|     1.0|          2|   1.0|38.0|71.2833|   1.0|    1.0|[1.0,38.0,71.2833...|\n",
      "|     1.0|          3|   3.0|26.0|  7.925|   1.0|    0.0|[3.0,26.0,7.92500...|\n",
      "|     1.0|          4|   1.0|35.0|   53.1|   1.0|    0.0|[1.0,35.0,53.0999...|\n",
      "|     0.0|          5|   3.0|35.0|   8.05|   0.0|    0.0|[3.0,35.0,8.05000...|\n",
      "|     0.0|          6|   3.0| 0.0| 8.4583|   0.0|    2.0|[3.0,0.0,8.458299...|\n",
      "|     0.0|          7|   1.0|54.0|51.8625|   0.0|    0.0|[1.0,54.0,51.8624...|\n",
      "|     0.0|          8|   3.0| 2.0| 21.075|   0.0|    0.0|[3.0,2.0,21.07500...|\n",
      "|     1.0|          9|   3.0|27.0|11.1333|   1.0|    0.0|[3.0,27.0,11.1332...|\n",
      "|     1.0|         10|   2.0|14.0|30.0708|   1.0|    1.0|[2.0,14.0,30.0708...|\n",
      "|     1.0|         11|   3.0| 4.0|   16.7|   1.0|    0.0|[3.0,4.0,16.70000...|\n",
      "|     1.0|         12|   1.0|58.0|  26.55|   1.0|    0.0|[1.0,58.0,26.5499...|\n",
      "|     0.0|         13|   3.0|20.0|   8.05|   0.0|    0.0|[3.0,20.0,8.05000...|\n",
      "|     0.0|         14|   3.0|39.0| 31.275|   0.0|    0.0|[3.0,39.0,31.2749...|\n",
      "|     0.0|         15|   3.0|14.0| 7.8542|   1.0|    0.0|[3.0,14.0,7.85419...|\n",
      "|     1.0|         16|   2.0|55.0|   16.0|   1.0|    0.0|[2.0,55.0,16.0,1....|\n",
      "|     0.0|         17|   3.0| 2.0| 29.125|   0.0|    2.0|[3.0,2.0,29.125,0...|\n",
      "|     1.0|         18|   2.0| 0.0|   13.0|   0.0|    0.0|(5,[0,2],[2.0,13.0])|\n",
      "|     0.0|         19|   3.0|31.0|   18.0|   1.0|    0.0|[3.0,31.0,18.0,1....|\n",
      "|     1.0|         20|   3.0| 0.0|  7.225|   1.0|    1.0|[3.0,0.0,7.224999...|\n",
      "+--------+-----------+------+----+-------+------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+------+----+-------+------+-------+--------------------+\n",
      "|PassengerId|Pclass| Age|   Fare|Gender|Boarded|            features|\n",
      "+-----------+------+----+-------+------+-------+--------------------+\n",
      "|        892|   3.0|34.5| 7.8292|   0.0|    2.0|[3.0,34.5,7.82919...|\n",
      "|        893|   3.0|47.0|    7.0|   1.0|    0.0|[3.0,47.0,7.0,1.0...|\n",
      "|        894|   2.0|62.0| 9.6875|   0.0|    2.0|[2.0,62.0,9.6875,...|\n",
      "|        895|   3.0|27.0| 8.6625|   0.0|    0.0|[3.0,27.0,8.66250...|\n",
      "|        896|   3.0|22.0|12.2875|   1.0|    0.0|[3.0,22.0,12.2875...|\n",
      "|        897|   3.0|14.0|  9.225|   0.0|    0.0|[3.0,14.0,9.22500...|\n",
      "|        898|   3.0|30.0| 7.6292|   1.0|    2.0|[3.0,30.0,7.62919...|\n",
      "|        899|   2.0|26.0|   29.0|   0.0|    0.0|[2.0,26.0,29.0,0....|\n",
      "|        900|   3.0|18.0| 7.2292|   1.0|    1.0|[3.0,18.0,7.22919...|\n",
      "|        901|   3.0|21.0|  24.15|   0.0|    0.0|[3.0,21.0,24.1499...|\n",
      "|        902|   3.0| 0.0| 7.8958|   0.0|    0.0|(5,[0,2],[3.0,7.8...|\n",
      "|        903|   1.0|46.0|   26.0|   0.0|    0.0|[1.0,46.0,26.0,0....|\n",
      "|        904|   1.0|23.0|82.2667|   1.0|    0.0|[1.0,23.0,82.2667...|\n",
      "|        905|   2.0|63.0|   26.0|   0.0|    0.0|[2.0,63.0,26.0,0....|\n",
      "|        906|   1.0|47.0| 61.175|   1.0|    0.0|[1.0,47.0,61.1749...|\n",
      "|        907|   2.0|24.0|27.7208|   1.0|    1.0|[2.0,24.0,27.7208...|\n",
      "|        908|   2.0|35.0|  12.35|   0.0|    2.0|[2.0,35.0,12.3500...|\n",
      "|        909|   3.0|21.0|  7.225|   0.0|    1.0|[3.0,21.0,7.22499...|\n",
      "|        910|   3.0|27.0|  7.925|   1.0|    0.0|[3.0,27.0,7.92500...|\n",
      "|        911|   3.0|45.0|  7.225|   1.0|    1.0|[3.0,45.0,7.22499...|\n",
      "+-----------+------+----+-------+------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_training_data.show()\n",
    "transformed_test_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point our data prep is done\n",
    "# We will start Modeling now..\n",
    "\n",
    "# As we have seperate training and testing data, we will use that as it is!\n",
    "training_data = transformed_training_data\n",
    "test_data = transformed_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and fit an ML model to our dataset to predict the “Survived” columns with all the other ones. \n",
    "# We will be using a Random Forest Classifier. This is actually an estimator that we have to fit.\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier # todo\n",
    "rf = RandomForestClassifier(labelCol='Survived', \n",
    "                            featuresCol='features',\n",
    "                            maxDepth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel (uid=RandomForestClassifier_b1a82afd3c0f) with 20 trees"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we fit (train) the model with training data\n",
    "model = rf.fit(training_data)\n",
    "\n",
    "# This will give us something called a transformer.\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Pclass: float, Age: float, Fare: float, Gender: double, Boarded: double, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And finally, we predict using the test dataset\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----+-------+------+-------+--------------------+--------------------+--------------------+----------+\n",
      "|PassengerId|Pclass| Age|   Fare|Gender|Boarded|            features|       rawPrediction|         probability|prediction|\n",
      "+-----------+------+----+-------+------+-------+--------------------+--------------------+--------------------+----------+\n",
      "|        892|   3.0|34.5| 7.8292|   0.0|    2.0|[3.0,34.5,7.82919...|[18.2556167583500...|[0.91278083791750...|       0.0|\n",
      "|        893|   3.0|47.0|    7.0|   1.0|    0.0|[3.0,47.0,7.0,1.0...|[13.9587964748052...|[0.69793982374026...|       0.0|\n",
      "|        894|   2.0|62.0| 9.6875|   0.0|    2.0|[2.0,62.0,9.6875,...|[17.6730740705420...|[0.88365370352710...|       0.0|\n",
      "|        895|   3.0|27.0| 8.6625|   0.0|    0.0|[3.0,27.0,8.66250...|[17.2658843674402...|[0.86329421837201...|       0.0|\n",
      "|        896|   3.0|22.0|12.2875|   1.0|    0.0|[3.0,22.0,12.2875...|[9.48490656769818...|[0.47424532838490...|       1.0|\n",
      "|        897|   3.0|14.0|  9.225|   0.0|    0.0|[3.0,14.0,9.22500...|[17.3051821614748...|[0.86525910807374...|       0.0|\n",
      "|        898|   3.0|30.0| 7.6292|   1.0|    2.0|[3.0,30.0,7.62919...|[7.80147031483370...|[0.39007351574168...|       1.0|\n",
      "|        899|   2.0|26.0|   29.0|   0.0|    0.0|[2.0,26.0,29.0,0....|[16.5289338922252...|[0.82644669461126...|       0.0|\n",
      "|        900|   3.0|18.0| 7.2292|   1.0|    1.0|[3.0,18.0,7.22919...|[5.56951352987842...|[0.27847567649392...|       1.0|\n",
      "|        901|   3.0|21.0|  24.15|   0.0|    0.0|[3.0,21.0,24.1499...|[17.0923856998131...|[0.85461928499065...|       0.0|\n",
      "|        902|   3.0| 0.0| 7.8958|   0.0|    0.0|(5,[0,2],[3.0,7.8...|[18.0371543721599...|[0.90185771860799...|       0.0|\n",
      "|        903|   1.0|46.0|   26.0|   0.0|    0.0|[1.0,46.0,26.0,0....|[16.4911056990094...|[0.82455528495047...|       0.0|\n",
      "|        904|   1.0|23.0|82.2667|   1.0|    0.0|[1.0,23.0,82.2667...|[0.66994462426334...|[0.03349723121316...|       1.0|\n",
      "|        905|   2.0|63.0|   26.0|   0.0|    0.0|[2.0,63.0,26.0,0....|[17.1782005021320...|[0.85891002510660...|       0.0|\n",
      "|        906|   1.0|47.0| 61.175|   1.0|    0.0|[1.0,47.0,61.1749...|[0.77353159699779...|[0.03867657984988...|       1.0|\n",
      "|        907|   2.0|24.0|27.7208|   1.0|    1.0|[2.0,24.0,27.7208...|[1.20333764946081...|[0.06016688247304...|       1.0|\n",
      "|        908|   2.0|35.0|  12.35|   0.0|    2.0|[2.0,35.0,12.3500...|[17.3914900623114...|[0.86957450311557...|       0.0|\n",
      "|        909|   3.0|21.0|  7.225|   0.0|    1.0|[3.0,21.0,7.22499...|[17.3466242648711...|[0.86733121324355...|       0.0|\n",
      "|        910|   3.0|27.0|  7.925|   1.0|    0.0|[3.0,27.0,7.92500...|[11.4545087767544...|[0.57272543883772...|       0.0|\n",
      "|        911|   3.0|45.0|  7.225|   1.0|    1.0|[3.0,45.0,7.22499...|[11.2581113000755...|[0.56290556500377...|       0.0|\n",
      "+-----------+------+----+-------+------+-------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Done! My first Spark ML model\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|PassengerId|Survived|\n",
      "+-----------+--------+\n",
      "|        892|       0|\n",
      "|        893|       0|\n",
      "|        894|       0|\n",
      "|        895|       0|\n",
      "|        896|       1|\n",
      "|        897|       0|\n",
      "|        898|       1|\n",
      "|        899|       0|\n",
      "|        900|       1|\n",
      "|        901|       0|\n",
      "|        902|       0|\n",
      "|        903|       0|\n",
      "|        904|       1|\n",
      "|        905|       0|\n",
      "|        906|       1|\n",
      "|        907|       1|\n",
      "|        908|       0|\n",
      "|        909|       0|\n",
      "|        910|       0|\n",
      "|        911|       0|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally saving the prediction to a local folder\n",
    "\n",
    "output_predictions = predictions.select(col('PassengerId').cast('int'),\n",
    "                                        col('prediction').cast('int').alias('Survived')\n",
    "                                       )\n",
    "\n",
    "output_predictions.show()\n",
    "output_predictions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_predictions.write.format('csv').option('header', True).mode('overwrite').option('sep',',').save('./build/')\n",
    "# Submit the prediction to https://www.kaggle.com/c/titanic/submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
