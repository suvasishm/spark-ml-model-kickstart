{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this learning process, I am tryig to build the following model:\n",
    "# Model: To Predict survival on the Titanic. Ref: https://www.kaggle.com/c/titanic/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://drsmmacbookpro:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x113665a58>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data into Spark using DataFrames\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Titanic Data').getOrCreate()\n",
    "\n",
    "spark # prints what's in the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Survived: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the training data and create a DataFrames\n",
    "df = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"./data/train.csv\"))\n",
    "\n",
    "df # prints the DF structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|   4|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|  58|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|  20|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|  39|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|  14|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|  55|    0|    0|          248706|     16| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|   2|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|     13| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|  31|    1|    0|          345763|     18| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show() # prints some records from the DF\n",
    "df.count() # prints count of records in the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-------+--------+\n",
      "|Survived|Pclass|   Sex| Age|   Fare|Embarked|\n",
      "+--------+------+------+----+-------+--------+\n",
      "|     0.0|   3.0|  male|22.0|   7.25|       S|\n",
      "|     1.0|   1.0|female|38.0|71.2833|       C|\n",
      "|     1.0|   3.0|female|26.0|  7.925|       S|\n",
      "|     1.0|   1.0|female|35.0|   53.1|       S|\n",
      "|     0.0|   3.0|  male|35.0|   8.05|       S|\n",
      "|     0.0|   3.0|  male|null| 8.4583|       Q|\n",
      "|     0.0|   1.0|  male|54.0|51.8625|       S|\n",
      "|     0.0|   3.0|  male| 2.0| 21.075|       S|\n",
      "|     1.0|   3.0|female|27.0|11.1333|       S|\n",
      "|     1.0|   2.0|female|14.0|30.0708|       C|\n",
      "|     1.0|   3.0|female| 4.0|   16.7|       S|\n",
      "|     1.0|   1.0|female|58.0|  26.55|       S|\n",
      "|     0.0|   3.0|  male|20.0|   8.05|       S|\n",
      "|     0.0|   3.0|  male|39.0| 31.275|       S|\n",
      "|     0.0|   3.0|female|14.0| 7.8542|       S|\n",
      "|     1.0|   2.0|female|55.0|   16.0|       S|\n",
      "|     0.0|   3.0|  male| 2.0| 29.125|       Q|\n",
      "|     1.0|   2.0|  male|null|   13.0|       S|\n",
      "|     0.0|   3.0|female|31.0|   18.0|       S|\n",
      "|     1.0|   3.0|female|null|  7.225|       C|\n",
      "+--------+------+------+----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare a dataset by casting some of columns to required type!\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "dataset = df.select(col('Survived').cast('float'),\n",
    "                         col('Pclass').cast('float'),\n",
    "                         col('Sex'),\n",
    "                         col('Age').cast('float'),\n",
    "                         col('Fare').cast('float'),\n",
    "                         col('Embarked')\n",
    "                        )\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+---+----+--------+\n",
      "|Survived|Pclass|Sex|Age|Fare|Embarked|\n",
      "+--------+------+---+---+----+--------+\n",
      "|       0|     0|  0|177|   0|       2|\n",
      "+--------+------+---+---+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "dataset.select([count(when(isnull(c), c)).alias(c) for c in dataset.columns]).show() # todo: learn to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-------+------+-------+\n",
      "|Survived|Pclass| Age|   Fare|Gender|Boarded|\n",
      "+--------+------+----+-------+------+-------+\n",
      "|     0.0|   3.0|22.0|   7.25|   0.0|    0.0|\n",
      "|     1.0|   1.0|38.0|71.2833|   1.0|    1.0|\n",
      "|     1.0|   3.0|26.0|  7.925|   1.0|    0.0|\n",
      "|     1.0|   1.0|35.0|   53.1|   1.0|    0.0|\n",
      "|     0.0|   3.0|35.0|   8.05|   0.0|    0.0|\n",
      "|     0.0|   1.0|54.0|51.8625|   0.0|    0.0|\n",
      "|     0.0|   3.0| 2.0| 21.075|   0.0|    0.0|\n",
      "|     1.0|   3.0|27.0|11.1333|   1.0|    0.0|\n",
      "|     1.0|   2.0|14.0|30.0708|   1.0|    1.0|\n",
      "|     1.0|   3.0| 4.0|   16.7|   1.0|    0.0|\n",
      "|     1.0|   1.0|58.0|  26.55|   1.0|    0.0|\n",
      "|     0.0|   3.0|20.0|   8.05|   0.0|    0.0|\n",
      "|     0.0|   3.0|39.0| 31.275|   0.0|    0.0|\n",
      "|     0.0|   3.0|14.0| 7.8542|   1.0|    0.0|\n",
      "|     1.0|   2.0|55.0|   16.0|   1.0|    0.0|\n",
      "|     0.0|   3.0| 2.0| 29.125|   0.0|    2.0|\n",
      "|     0.0|   3.0|31.0|   18.0|   1.0|    0.0|\n",
      "|     0.0|   2.0|35.0|   26.0|   0.0|    0.0|\n",
      "|     1.0|   2.0|34.0|   13.0|   0.0|    0.0|\n",
      "|     1.0|   3.0|15.0| 8.0292|   1.0|    2.0|\n",
      "+--------+------+----+-------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminate rows with null values in columns\n",
    "dataset = dataset.replace('?', None).dropna(how='any') # todo: learn the Dataset API\n",
    "dataset.show()\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-------+--------+------+-------+\n",
      "|Survived|Pclass|   Sex| Age|   Fare|Embarked|Gender|Boarded|\n",
      "+--------+------+------+----+-------+--------+------+-------+\n",
      "|     0.0|   3.0|  male|22.0|   7.25|       S|   0.0|    0.0|\n",
      "|     1.0|   1.0|female|38.0|71.2833|       C|   1.0|    1.0|\n",
      "|     1.0|   3.0|female|26.0|  7.925|       S|   1.0|    0.0|\n",
      "|     1.0|   1.0|female|35.0|   53.1|       S|   1.0|    0.0|\n",
      "|     0.0|   3.0|  male|35.0|   8.05|       S|   0.0|    0.0|\n",
      "|     0.0|   1.0|  male|54.0|51.8625|       S|   0.0|    0.0|\n",
      "|     0.0|   3.0|  male| 2.0| 21.075|       S|   0.0|    0.0|\n",
      "|     1.0|   3.0|female|27.0|11.1333|       S|   1.0|    0.0|\n",
      "|     1.0|   2.0|female|14.0|30.0708|       C|   1.0|    1.0|\n",
      "|     1.0|   3.0|female| 4.0|   16.7|       S|   1.0|    0.0|\n",
      "|     1.0|   1.0|female|58.0|  26.55|       S|   1.0|    0.0|\n",
      "|     0.0|   3.0|  male|20.0|   8.05|       S|   0.0|    0.0|\n",
      "|     0.0|   3.0|  male|39.0| 31.275|       S|   0.0|    0.0|\n",
      "|     0.0|   3.0|female|14.0| 7.8542|       S|   1.0|    0.0|\n",
      "|     1.0|   2.0|female|55.0|   16.0|       S|   1.0|    0.0|\n",
      "|     0.0|   3.0|  male| 2.0| 29.125|       Q|   0.0|    2.0|\n",
      "|     0.0|   3.0|female|31.0|   18.0|       S|   1.0|    0.0|\n",
      "|     0.0|   2.0|  male|35.0|   26.0|       S|   0.0|    0.0|\n",
      "|     1.0|   2.0|  male|34.0|   13.0|       S|   0.0|    0.0|\n",
      "|     1.0|   3.0|female|15.0| 8.0292|       Q|   1.0|    2.0|\n",
      "+--------+------+------+----+-------+--------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark ML library only works with numeric data. \n",
    "# But we still want to use the Sex and the Embarked column. \n",
    "# For that, we will need to encode (transform) them. Sex -> Gender; Embarked -> Boarded\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer # todo: learn Spark ML API\n",
    "dataset = StringIndexer(\n",
    "    inputCol='Sex', \n",
    "    outputCol='Gender', \n",
    "    handleInvalid='keep').fit(dataset).transform(dataset)\n",
    "dataset = StringIndexer(\n",
    "    inputCol='Embarked', \n",
    "    outputCol='Boarded', \n",
    "    handleInvalid='keep').fit(dataset).transform(dataset)\n",
    "\n",
    "dataset.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Survived', 'float'),\n",
       " ('Pclass', 'float'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'float'),\n",
       " ('Fare', 'float'),\n",
       " ('Embarked', 'string'),\n",
       " ('Gender', 'double'),\n",
       " ('Boarded', 'double')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-------+------+-------+\n",
      "|Survived|Pclass| Age|   Fare|Gender|Boarded|\n",
      "+--------+------+----+-------+------+-------+\n",
      "|     0.0|   3.0|22.0|   7.25|   0.0|    0.0|\n",
      "|     1.0|   1.0|38.0|71.2833|   1.0|    1.0|\n",
      "|     1.0|   3.0|26.0|  7.925|   1.0|    0.0|\n",
      "|     1.0|   1.0|35.0|   53.1|   1.0|    0.0|\n",
      "|     0.0|   3.0|35.0|   8.05|   0.0|    0.0|\n",
      "|     0.0|   1.0|54.0|51.8625|   0.0|    0.0|\n",
      "|     0.0|   3.0| 2.0| 21.075|   0.0|    0.0|\n",
      "|     1.0|   3.0|27.0|11.1333|   1.0|    0.0|\n",
      "|     1.0|   2.0|14.0|30.0708|   1.0|    1.0|\n",
      "|     1.0|   3.0| 4.0|   16.7|   1.0|    0.0|\n",
      "|     1.0|   1.0|58.0|  26.55|   1.0|    0.0|\n",
      "|     0.0|   3.0|20.0|   8.05|   0.0|    0.0|\n",
      "|     0.0|   3.0|39.0| 31.275|   0.0|    0.0|\n",
      "|     0.0|   3.0|14.0| 7.8542|   1.0|    0.0|\n",
      "|     1.0|   2.0|55.0|   16.0|   1.0|    0.0|\n",
      "|     0.0|   3.0| 2.0| 29.125|   0.0|    2.0|\n",
      "|     0.0|   3.0|31.0|   18.0|   1.0|    0.0|\n",
      "|     0.0|   2.0|35.0|   26.0|   0.0|    0.0|\n",
      "|     1.0|   2.0|34.0|   13.0|   0.0|    0.0|\n",
      "|     1.0|   3.0|15.0| 8.0292|   1.0|    2.0|\n",
      "+--------+------+----+-------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "dataset = dataset.drop('Sex')\n",
    "dataset = dataset.drop('Embarked')\n",
    "dataset.show()\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Survived: float, Pclass: float, Age: float, Fare: float, Gender: double, Boarded: double, features: vector]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark works to predict with a column with all the features smashed together into a list-like structure.\n",
    "# I want to predict “Survived”, I need to combine the information other columns into one column.\n",
    "# That column is called \"features\" and it's value should look like say [3.0, 22.0, 7.25, 0, 0]\n",
    "\n",
    "# Assemble all the features with VectorAssembler\n",
    "required_features = ['Pclass',\n",
    "                    'Age',\n",
    "                    'Fare',\n",
    "                    'Gender',\n",
    "                    'Boarded'\n",
    "                   ]\n",
    "from pyspark.ml.feature import VectorAssembler # todo\n",
    "assembler = VectorAssembler(inputCols=required_features, outputCol='features')\n",
    "transformed_data = assembler.transform(dataset)\n",
    "\n",
    "transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-------+------+-------+--------------------+\n",
      "|Survived|Pclass| Age|   Fare|Gender|Boarded|            features|\n",
      "+--------+------+----+-------+------+-------+--------------------+\n",
      "|     0.0|   3.0|22.0|   7.25|   0.0|    0.0|[3.0,22.0,7.25,0....|\n",
      "|     1.0|   1.0|38.0|71.2833|   1.0|    1.0|[1.0,38.0,71.2833...|\n",
      "|     1.0|   3.0|26.0|  7.925|   1.0|    0.0|[3.0,26.0,7.92500...|\n",
      "|     1.0|   1.0|35.0|   53.1|   1.0|    0.0|[1.0,35.0,53.0999...|\n",
      "|     0.0|   3.0|35.0|   8.05|   0.0|    0.0|[3.0,35.0,8.05000...|\n",
      "|     0.0|   1.0|54.0|51.8625|   0.0|    0.0|[1.0,54.0,51.8624...|\n",
      "|     0.0|   3.0| 2.0| 21.075|   0.0|    0.0|[3.0,2.0,21.07500...|\n",
      "|     1.0|   3.0|27.0|11.1333|   1.0|    0.0|[3.0,27.0,11.1332...|\n",
      "|     1.0|   2.0|14.0|30.0708|   1.0|    1.0|[2.0,14.0,30.0708...|\n",
      "|     1.0|   3.0| 4.0|   16.7|   1.0|    0.0|[3.0,4.0,16.70000...|\n",
      "|     1.0|   1.0|58.0|  26.55|   1.0|    0.0|[1.0,58.0,26.5499...|\n",
      "|     0.0|   3.0|20.0|   8.05|   0.0|    0.0|[3.0,20.0,8.05000...|\n",
      "|     0.0|   3.0|39.0| 31.275|   0.0|    0.0|[3.0,39.0,31.2749...|\n",
      "|     0.0|   3.0|14.0| 7.8542|   1.0|    0.0|[3.0,14.0,7.85419...|\n",
      "|     1.0|   2.0|55.0|   16.0|   1.0|    0.0|[2.0,55.0,16.0,1....|\n",
      "|     0.0|   3.0| 2.0| 29.125|   0.0|    2.0|[3.0,2.0,29.125,0...|\n",
      "|     0.0|   3.0|31.0|   18.0|   1.0|    0.0|[3.0,31.0,18.0,1....|\n",
      "|     0.0|   2.0|35.0|   26.0|   0.0|    0.0|[2.0,35.0,26.0,0....|\n",
      "|     1.0|   2.0|34.0|   13.0|   0.0|    0.0|[2.0,34.0,13.0,0....|\n",
      "|     1.0|   3.0|15.0| 8.0292|   1.0|    2.0|[3.0,15.0,8.02919...|\n",
      "+--------+------+----+-------+------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data.show()\n",
    "transformed_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point our data prep is done\n",
    "# We will start Modeling now.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before modeling let’s do the usual splitting between training and testing\n",
    "(training_data, test_data) = transformed_data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+--------+------+-------+--------------------+\n",
      "|Survived|Pclass| Age|    Fare|Gender|Boarded|            features|\n",
      "+--------+------+----+--------+------+-------+--------------------+\n",
      "|     0.0|   1.0| 2.0|  151.55|   1.0|    0.0|[1.0,2.0,151.5500...|\n",
      "|     0.0|   1.0|19.0|    53.1|   0.0|    0.0|[1.0,19.0,53.0999...|\n",
      "|     0.0|   1.0|19.0|   263.0|   0.0|    0.0|[1.0,19.0,263.0,0...|\n",
      "|     0.0|   1.0|21.0| 77.2875|   0.0|    0.0|[1.0,21.0,77.2874...|\n",
      "|     0.0|   1.0|22.0|135.6333|   0.0|    1.0|[1.0,22.0,135.633...|\n",
      "|     0.0|   1.0|24.0|    79.2|   0.0|    1.0|[1.0,24.0,79.1999...|\n",
      "|     0.0|   1.0|27.0|   211.5|   0.0|    1.0|[1.0,27.0,211.5,0...|\n",
      "|     0.0|   1.0|29.0|    30.0|   0.0|    0.0|[1.0,29.0,30.0,0....|\n",
      "|     0.0|   1.0|29.0|    66.6|   0.0|    0.0|[1.0,29.0,66.5999...|\n",
      "|     0.0|   1.0|30.0|   27.75|   0.0|    1.0|[1.0,30.0,27.75,0...|\n",
      "|     0.0|   1.0|31.0| 50.4958|   0.0|    0.0|[1.0,31.0,50.4958...|\n",
      "|     0.0|   1.0|33.0|     5.0|   0.0|    0.0|[1.0,33.0,5.0,0.0...|\n",
      "|     0.0|   1.0|36.0|  40.125|   0.0|    1.0|[1.0,36.0,40.125,...|\n",
      "|     0.0|   1.0|36.0|   78.85|   0.0|    0.0|[1.0,36.0,78.8499...|\n",
      "|     0.0|   1.0|37.0|    53.1|   0.0|    0.0|[1.0,37.0,53.0999...|\n",
      "|     0.0|   1.0|38.0|153.4625|   0.0|    0.0|[1.0,38.0,153.462...|\n",
      "|     0.0|   1.0|39.0|     0.0|   0.0|    0.0|(5,[0,1],[1.0,39.0])|\n",
      "|     0.0|   1.0|40.0|     0.0|   0.0|    0.0|(5,[0,1],[1.0,40.0])|\n",
      "|     0.0|   1.0|40.0| 27.7208|   0.0|    1.0|[1.0,40.0,27.7208...|\n",
      "|     0.0|   1.0|42.0|    52.0|   0.0|    0.0|[1.0,42.0,52.0,0....|\n",
      "+--------+------+----+--------+------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "590"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We randomly select 80% of the transformed data and use it as training_data\n",
    "training_data.show()\n",
    "training_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+--------+------+-------+--------------------+\n",
      "|Survived|Pclass| Age|    Fare|Gender|Boarded|            features|\n",
      "+--------+------+----+--------+------+-------+--------------------+\n",
      "|     0.0|   1.0|18.0|   108.9|   0.0|    1.0|[1.0,18.0,108.900...|\n",
      "|     0.0|   1.0|24.0|247.5208|   0.0|    1.0|[1.0,24.0,247.520...|\n",
      "|     0.0|   1.0|25.0|  151.55|   1.0|    0.0|[1.0,25.0,151.550...|\n",
      "|     0.0|   1.0|28.0|    47.1|   0.0|    0.0|[1.0,28.0,47.0999...|\n",
      "|     0.0|   1.0|28.0| 82.1708|   0.0|    1.0|[1.0,28.0,82.1707...|\n",
      "|     0.0|   1.0|31.0|    52.0|   0.0|    0.0|[1.0,31.0,52.0,0....|\n",
      "|     0.0|   1.0|37.0|    29.7|   0.0|    1.0|[1.0,37.0,29.7000...|\n",
      "|     0.0|   1.0|38.0|     0.0|   0.0|    0.0|(5,[0,1],[1.0,38.0])|\n",
      "|     0.0|   1.0|45.0|    35.5|   0.0|    0.0|[1.0,45.0,35.5,0....|\n",
      "|     0.0|   1.0|47.0| 25.5875|   0.0|    0.0|[1.0,47.0,25.5874...|\n",
      "|     0.0|   1.0|49.0|110.8833|   0.0|    1.0|[1.0,49.0,110.883...|\n",
      "|     0.0|   1.0|54.0| 51.8625|   0.0|    0.0|[1.0,54.0,51.8624...|\n",
      "|     0.0|   1.0|58.0|    29.7|   0.0|    1.0|[1.0,58.0,29.7000...|\n",
      "|     0.0|   1.0|61.0|    33.5|   0.0|    0.0|[1.0,61.0,33.5,0....|\n",
      "|     0.0|   2.0|23.0| 15.0458|   0.0|    1.0|[2.0,23.0,15.0458...|\n",
      "|     0.0|   2.0|24.0|    13.0|   0.0|    0.0|[2.0,24.0,13.0,0....|\n",
      "|     0.0|   2.0|24.0|    73.5|   0.0|    0.0|[2.0,24.0,73.5,0....|\n",
      "|     0.0|   2.0|25.0|    13.0|   0.0|    0.0|[2.0,25.0,13.0,0....|\n",
      "|     0.0|   2.0|27.0|    13.0|   0.0|    0.0|[2.0,27.0,13.0,0....|\n",
      "|     0.0|   2.0|31.0| 37.0042|   0.0|    1.0|[2.0,31.0,37.0041...|\n",
      "+--------+------+----+--------+------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remaining 20% as test_data\n",
    "\n",
    "test_data.show()\n",
    "test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and fit an ML model to our dataset to predict the “Survived” columns with all the other ones. \n",
    "# We will be using a Random Forest Classifier. This is actually an estimator that we have to fit.\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier # todo\n",
    "rf = RandomForestClassifier(labelCol='Survived', \n",
    "                            featuresCol='features',\n",
    "                            maxDepth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel (uid=RandomForestClassifier_9beba4e5d150) with 20 trees"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we fit the model\n",
    "model = rf.fit(training_data)\n",
    "\n",
    "# This will give us something called a transformer.\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Survived: float, Pclass: float, Age: float, Fare: float, Gender: double, Boarded: double, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And finally, we predict using the test dataset\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+--------+------+-------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass| Age|    Fare|Gender|Boarded|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+----+--------+------+-------+--------------------+--------------------+--------------------+----------+\n",
      "|     0.0|   1.0|18.0|   108.9|   0.0|    1.0|[1.0,18.0,108.900...|[11.6333451394326...|[0.58166725697163...|       0.0|\n",
      "|     0.0|   1.0|24.0|247.5208|   0.0|    1.0|[1.0,24.0,247.520...|[11.3909573189198...|[0.56954786594599...|       0.0|\n",
      "|     0.0|   1.0|25.0|  151.55|   1.0|    0.0|[1.0,25.0,151.550...|[0.93400643275822...|[0.04670032163791...|       1.0|\n",
      "|     0.0|   1.0|28.0|    47.1|   0.0|    0.0|[1.0,28.0,47.0999...|[9.77377106754905...|[0.48868855337745...|       1.0|\n",
      "|     0.0|   1.0|28.0| 82.1708|   0.0|    1.0|[1.0,28.0,82.1707...|[9.87266677689661...|[0.49363333884483...|       1.0|\n",
      "|     0.0|   1.0|31.0|    52.0|   0.0|    0.0|[1.0,31.0,52.0,0....|[10.4059139246919...|[0.52029569623459...|       0.0|\n",
      "|     0.0|   1.0|37.0|    29.7|   0.0|    1.0|[1.0,37.0,29.7000...|[8.40570318619840...|[0.42028515930992...|       1.0|\n",
      "|     0.0|   1.0|38.0|     0.0|   0.0|    0.0|(5,[0,1],[1.0,38.0])|[17.3919808632852...|[0.86959904316426...|       0.0|\n",
      "|     0.0|   1.0|45.0|    35.5|   0.0|    0.0|[1.0,45.0,35.5,0....|[12.1724063816039...|[0.60862031908019...|       0.0|\n",
      "|     0.0|   1.0|47.0| 25.5875|   0.0|    0.0|[1.0,47.0,25.5874...|[13.4046114095140...|[0.67023057047570...|       0.0|\n",
      "|     0.0|   1.0|49.0|110.8833|   0.0|    1.0|[1.0,49.0,110.883...|[10.1703465351572...|[0.50851732675786...|       0.0|\n",
      "|     0.0|   1.0|54.0| 51.8625|   0.0|    0.0|[1.0,54.0,51.8624...|[13.5428099355131...|[0.67714049677565...|       0.0|\n",
      "|     0.0|   1.0|58.0|    29.7|   0.0|    1.0|[1.0,58.0,29.7000...|[11.8000379125099...|[0.59000189562549...|       0.0|\n",
      "|     0.0|   1.0|61.0|    33.5|   0.0|    0.0|[1.0,61.0,33.5,0....|[15.8278690710657...|[0.79139345355328...|       0.0|\n",
      "|     0.0|   2.0|23.0| 15.0458|   0.0|    1.0|[2.0,23.0,15.0458...|[15.0272452757203...|[0.75136226378601...|       0.0|\n",
      "|     0.0|   2.0|24.0|    13.0|   0.0|    0.0|[2.0,24.0,13.0,0....|[17.8212469523505...|[0.89106234761752...|       0.0|\n",
      "|     0.0|   2.0|24.0|    73.5|   0.0|    0.0|[2.0,24.0,73.5,0....|[16.3560793457955...|[0.81780396728977...|       0.0|\n",
      "|     0.0|   2.0|25.0|    13.0|   0.0|    0.0|[2.0,25.0,13.0,0....|[17.8212469523505...|[0.89106234761752...|       0.0|\n",
      "|     0.0|   2.0|27.0|    13.0|   0.0|    0.0|[2.0,27.0,13.0,0....|[16.8823470969018...|[0.84411735484509...|       0.0|\n",
      "|     0.0|   2.0|31.0| 37.0042|   0.0|    1.0|[2.0,31.0,37.0041...|[13.8807244784380...|[0.69403622392190...|       0.0|\n",
      "+--------+------+----+--------+------+-------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Done! My first Spark ML model\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassClassificationEvaluator_2c884964e7f0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model using a basic metric called the accuracy\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator # todo\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='Survived', \n",
    "    predictionCol='prediction', \n",
    "    metricName='accuracy')\n",
    "\n",
    "evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy =  0.8114754098360656\n"
     ]
    }
   ],
   "source": [
    "# And this gives me the accuracy\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Test Accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
